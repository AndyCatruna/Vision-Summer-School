{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNWp1iy17iSfQQkJuzZsqM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndyCatruna/Vision-Summer-School/blob/main/Lab_01_Neural_Networks_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Introduction to PyTorch"
      ],
      "metadata": {
        "id": "6d-6DC2Dof61"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this lab is to offer a short introduction to the PyTorch library and to help you construct and train a neural network.\n",
        "\n",
        "You should be familiar with numpy basics. Here is a short [tutorial](https://numpy.org/devdocs/user/quickstart.html) on numpy operations."
      ],
      "metadata": {
        "id": "vAdMzV81omQm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuWk21oSoVIJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensors\n",
        "\n",
        "PyTorch Tensors are similar to Numpy arrays, but have support for GPU acceleration and gradient computation. A tensor is a generalization of data structures that you are familiar with. For example a vector is a 1D tensor, and a matrix a 2D tensor. Most operations with torch tensors are similar to those of Numpy arrays."
      ],
      "metadata": {
        "id": "fukChWP6p83z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialization"
      ],
      "metadata": {
        "id": "oFodaKIXrZQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating an empty tensor"
      ],
      "metadata": {
        "id": "wQEYDBZaE7xe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([])\n",
        "print(a)"
      ],
      "metadata": {
        "id": "EiLd2AHsrc5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a tensor with specific size"
      ],
      "metadata": {
        "id": "v4wtOdUXFAF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.tensor((3, 4))  # Creates a tensor of size 3x4 filled with uninitialized values\n",
        "print(b)"
      ],
      "metadata": {
        "id": "XfWTqKx0r5Iv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a tensor from a list"
      ],
      "metadata": {
        "id": "D6YLaO3SFGYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = torch.tensor([[1, 2], [3, 4]])\n",
        "print(c)"
      ],
      "metadata": {
        "id": "X4E9P0f3r-at"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting a NumPy array to a tensor"
      ],
      "metadata": {
        "id": "Xt3PDMosFKNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array_data = np.array([1, 2, 3, 4, 5])\n",
        "d = torch.from_numpy(array_data)\n",
        "print(d)"
      ],
      "metadata": {
        "id": "ZF7NCseAsCG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a tensor with random values between 0 and 1 with specific shape"
      ],
      "metadata": {
        "id": "9qDXl4DzFNzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = torch.rand(2, 2)\n",
        "print(e)"
      ],
      "metadata": {
        "id": "Il9OwnevsXMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Shape of tensor"
      ],
      "metadata": {
        "id": "w_5DNlL4svEu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dimensions of a tensor can be checked with `.shape` attribute or `.size()` function."
      ],
      "metadata": {
        "id": "uIDrC8xYFVEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(5,3,2)\n",
        "\n",
        "shape = x.shape\n",
        "print(\"Shape:\", x.shape)\n",
        "\n",
        "size = x.size()\n",
        "print(\"Size:\", size)\n",
        "\n",
        "dim1, dim2, dim3 = x.size()\n",
        "print(\"Size:\", dim1, dim2, dim3)"
      ],
      "metadata": {
        "id": "FRVu_8GKstA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Operations with tensors"
      ],
      "metadata": {
        "id": "kYiujLGYtM0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors support most mathematical operations, similar to numpy arrays"
      ],
      "metadata": {
        "id": "6-02igpQFfyE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addition"
      ],
      "metadata": {
        "id": "vyaVRCTnFte3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.tensor([[1,2], [3,4], [5,6]])\n",
        "b = torch.rand(3,2)\n",
        "\n",
        "c = a + b\n",
        "\n",
        "print(\"a\", a)\n",
        "print(\"b\", b)\n",
        "print(\"c\", c)"
      ],
      "metadata": {
        "id": "98dWnk_JtPve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elementwise Multiplication"
      ],
      "metadata": {
        "id": "mbmJvO6_FwCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = a * b\n",
        "print(d)"
      ],
      "metadata": {
        "id": "18JkwMVztzUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing shape of tensor"
      ],
      "metadata": {
        "id": "Upa4riBXF0Km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = torch.arange(6)\n",
        "print(\"Before\", e)\n",
        "e = e.view(2,3)\n",
        "print(\"After\", e)"
      ],
      "metadata": {
        "id": "KBLQJeAkt5PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matrix Multiplication"
      ],
      "metadata": {
        "id": "1f5AI37ZF4iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = torch.matmul(a,e)\n",
        "print(f)"
      ],
      "metadata": {
        "id": "1UvJwP72uRoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(16)\n",
        "x = x.view(2, 2, 4)\n",
        "print(x)\n",
        "print(x.shape)"
      ],
      "metadata": {
        "id": "621D1c36uwrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing"
      ],
      "metadata": {
        "id": "D1Wd3pnyF9MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x[0])\n",
        "print(x[:, 0])\n",
        "print(x[:,:,0])\n",
        "print(x[:,:,1:3])"
      ],
      "metadata": {
        "id": "QPcxb6hHvALl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Computation Graph"
      ],
      "metadata": {
        "id": "dmelWkWBv1c5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient tracking refers to the ability to automatically compute gradients of a function with respect to its inputs or parameters."
      ],
      "metadata": {
        "id": "JAa2AbTIxHFh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, tensors do not keep track of gradients. This can be checked with the `requires_grad` attribute."
      ],
      "metadata": {
        "id": "10HcIM1PxUEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 3.0])\n",
        "x.requires_grad"
      ],
      "metadata": {
        "id": "i_KOCJqHv4Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can change this by setting `requires_grad` to `True`"
      ],
      "metadata": {
        "id": "xBtzmFp0xik4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.requires_grad_(True)\n",
        "print(x.requires_grad)\n",
        "\n",
        "y = torch.tensor([3.0, 4.0], requires_grad=True)\n",
        "print(y.requires_grad)"
      ],
      "metadata": {
        "id": "QAn1M1cOxqKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the `grad_fn` attribute. It saves the last function that was performed on that tensor so it can compute its gradient (derivative)."
      ],
      "metadata": {
        "id": "cVtM5SIsyzms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "z = x * y\n",
        "print(z)\n",
        "\n",
        "z = x ** 2\n",
        "print(z)\n",
        "\n",
        "z = x.mean()\n",
        "print(z)"
      ],
      "metadata": {
        "id": "rUg5r_VoydgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compute gradients using the `backward()` function. We can check the gradients with the `.grad` attribute."
      ],
      "metadata": {
        "id": "z8Z-RjmAzIv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 3.0], requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "y = x + 2\n",
        "print(y)\n",
        "\n",
        "z = y * y * 3\n",
        "z = z.mean()\n",
        "print(z)\n",
        "\n",
        "z.backward() # dz/dx\n",
        "print(\"Gradients of z with respect to x: \", x.grad)"
      ],
      "metadata": {
        "id": "eaVtALpAzFWM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPU"
      ],
      "metadata": {
        "id": "dqF49xpJ0Gji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this part you need to select Runtime -> Change Runtime type -> Hardware accelerator: GPU and press save. You will need to rerun all the cells."
      ],
      "metadata": {
        "id": "TQrqrDIP0IuA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep learning involves many operations that can be parallelized when working with tensors. Because of this, executing the computation on GPU leads to significantly faster processing."
      ],
      "metadata": {
        "id": "pAYo2TZf_W_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can check that GPU acceleration is available with the following command:"
      ],
      "metadata": {
        "id": "5Vd_DPl20zye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "9AgRT70s0371"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can specify the device on which all operations are done with the following command:"
      ],
      "metadata": {
        "id": "p08-re0F1M8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "9ZcoV4kr1WFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pushing a tensor on the GPU device is done with the `.to(...)` or `.cuda()` functions. All the operations performed with these tensors will be computed on the GPU."
      ],
      "metadata": {
        "id": "7Z0srxh01ctr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([2.0, 3.0])\n",
        "x = x.to(device)\n",
        "print(x)\n",
        "\n",
        "y = torch.tensor([5.0, 1.0]).to(device)\n",
        "print(y)\n",
        "\n",
        "z = x + y\n",
        "print(z)"
      ],
      "metadata": {
        "id": "3UkQcqB210tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2 - Training Neural Networks"
      ],
      "metadata": {
        "id": "ixUgxdA03Z0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Gradient Descent"
      ],
      "metadata": {
        "id": "AmLYgM667h3H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent is an optimization algorithm used to iteratively adjust model parameters based on the computed gradients, moving in the direction of steepest descent to find the optimal values that minimize the loss function.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/faq/gradient-optimization/ball.png\" width=400px>"
      ],
      "metadata": {
        "id": "FDw0Wq2G8E1X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent can be described by the following formula:\n",
        "\n",
        "<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20200611183120/1406-7.png\">\n",
        "\n",
        "where $\\theta$ are the weights (trainable parameters) of the model, $\\alpha$ is the learning rate and $J(\\theta)$ is the cost function (loss).\n",
        "\n",
        "The weights are updated in the opposite direction of the derivative (gradient) of the cost function. This basically changes the parameters so that the loss decreases.\n",
        "\n",
        "Remember that PyTorch can automatically track the gradients for us, which means we do not have to compute derivatives manually."
      ],
      "metadata": {
        "id": "Msv4hWK1HtLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The steps of training a neural network are the following:\n",
        "\n",
        "1. Initialize parameters.\n",
        "2. Compute loss.\n",
        "3. Calculate gradients of loss with respect to the parameters.\n",
        "4. Update parameters by moving in the opposite direction of the gradients.\n",
        "5. Repeat steps 2-4 for multiple epochs.\n",
        "6. Stop when a stopping condition is met (reaching a desired loss or number of epochs).\n",
        "\n"
      ],
      "metadata": {
        "id": "6nZm1REx9Ojk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Training a Linear Model"
      ],
      "metadata": {
        "id": "YQ2QAXZUIUO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train a simple linear model to learn the simple function $f(x) = 2*x$ using gradient descent in order to get familiar with the training pipeline.\n",
        "\n",
        "The model will have a single parameter $w \\in R$ and the output of the model will be $pred(x) = w * x$.\n",
        "\n",
        "The model should learn that $w = 2$ if we show it enough examples."
      ],
      "metadata": {
        "id": "Y57hYixT-zIn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a few examples that the model will see. $x$ is the input and $y$ is the ground truth."
      ],
      "metadata": {
        "id": "36uQusRGI7yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy dataset\n",
        "x = torch.tensor([1,2,3,4,5], dtype=torch.float32)\n",
        "y = torch.tensor([2,4,6,8,10], dtype=torch.float32)"
      ],
      "metadata": {
        "id": "7-H7GxCeJFWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the hyperparameters of training the model. These are chosen by the developer and can be changed to obtain better results"
      ],
      "metadata": {
        "id": "q7Tgjd2RJII1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "bWx5qSLCJS5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the weights of the model ($w=0$) and define the forward function (how the model obtains the output based on the input)."
      ],
      "metadata": {
        "id": "I00SV5-jJWLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize parameters\n",
        "weights = torch.tensor(0.0, requires_grad=True)\n",
        "\n",
        "# Define forward function for linear model\n",
        "def forward(x):\n",
        "  return weights * x"
      ],
      "metadata": {
        "id": "XBRw1i1qJs6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define the loss function $J$. This should tell us how close the model's predictions are to the ground truth. We choose mean absolute error as it is intuitive, but there are other loss functions. Most of them are already available in pytorch and we don't need to manually define them. You can check them [here](https://pytorch.org/docs/stable/nn.html#loss-functions)."
      ],
      "metadata": {
        "id": "wmAuJnuyJxYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the custom loss (mean absolute error)\n",
        "def custom_loss(pred, ground_truth):\n",
        "  return torch.abs(pred - ground_truth).mean()"
      ],
      "metadata": {
        "id": "BdHnupniKXwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to see if the model will be able to predict the correct answer even for unseen samples. For example, $6$ is not in the samples in $x$."
      ],
      "metadata": {
        "id": "slxVRv3RKvTn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  print(f\"Prediction before training: f(6) = {forward(6)}\")"
      ],
      "metadata": {
        "id": "AsPMP-x_LIIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform the training loop:\n",
        "* we obtain the model's prediction\n",
        "* we see how good the predictions are based on the loss\n",
        "* we update the model's weights in the direction that minimizes the loss."
      ],
      "metadata": {
        "id": "Ix3QustTLJlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  # Obtain prediction\n",
        "  pred = forward(x)\n",
        "\n",
        "  # 2. Compute loss\n",
        "  loss = custom_loss(pred, y)\n",
        "\n",
        "  # 3. Compute gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # Gradient of loss with respect to weights\n",
        "  dw = weights.grad\n",
        "\n",
        "  # 4. Update parameters (without grad so it does not mess with computation - this will be removed when working with torch optimizers)\n",
        "  with torch.no_grad():\n",
        "    weights -= (learning_rate * dw)\n",
        "\n",
        "  # Set gradient to 0 for next computation\n",
        "  weights.grad.zero_()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch}, weights = {weights}, loss = {loss}\")\n",
        "\n",
        "print(f\"Prediction after training: f(6) = {forward(6)}\")\n"
      ],
      "metadata": {
        "id": "GwCRoRqD-ZxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the final weight $w$ is not exactly equal to 2 but is very close.\n",
        "\n",
        "This can be improved with a smaller learning rate and maybe more training epochs.\n",
        "\n",
        "However, in machine learning we don't expect perfect solutions."
      ],
      "metadata": {
        "id": "U9Xx90LgLk4u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 1** - change the hyperparameters and observe how the progress of weights changes."
      ],
      "metadata": {
        "id": "ucfPVuHuE-4g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Luckily we do not have to manually perform the updates of the model.\n",
        "\n",
        "We can do this by defining the `optimizer = optim.SGD(...)` which does the gradient descent updates for us.\n",
        "\n",
        "Also, we do not need to manually define the weights. We can use `nn.Module` class and `nn.Linear(...)` for this."
      ],
      "metadata": {
        "id": "EfWyZHSCFkWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We construct a simple linear model by inheriting from `nn.Module` class.\n",
        "\n",
        "All neural networks you will build will inherit from this class. It's good to get familiar with it. You can check more details about it [here](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)."
      ],
      "metadata": {
        "id": "eFal4_O1IaN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LinearModel, self).__init__()\n",
        "    # One input neuron and one output neuron\n",
        "    self.weights = nn.Linear(in_features=1, out_features=1, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.weights(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "aykgJBFUIfiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the model and define the hyperparameters"
      ],
      "metadata": {
        "id": "MqR_NrriNJ1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Initialize parameters\n",
        "model = LinearModel()\n",
        "print(model)\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.01\n",
        "epochs = 100"
      ],
      "metadata": {
        "id": "f-f5SbfbNPBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize the optimizer. We will use `optim.SGD` which stands for Stochastic Gradient Descent. In the PyTorch library there are optimizers that may work better than Stochastic Gradient Descent (for example `optim.Adam` which is very commonly used). You can check them [here](https://pytorch.org/docs/stable/optim.html)"
      ],
      "metadata": {
        "id": "N6yY8S9HNSuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will perform Gradient Descent for us\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "OwsqZpdrNu7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The new model expects the samples to come in batches. We will add an extra dimension to our $x$ and $y$ tensors."
      ],
      "metadata": {
        "id": "M8CUNRJBNx6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, y.shape)\n",
        "# Add extra dimension for batch:\n",
        "x = x.unsqueeze(1)\n",
        "y = y.unsqueeze(1)\n",
        "print(x.shape, y.shape)\n",
        "\n",
        "# Define testing sample\n",
        "testing_sample = torch.tensor([[6.0]])"
      ],
      "metadata": {
        "id": "TL8wqhRlN7DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction on unseen sample before training"
      ],
      "metadata": {
        "id": "cdEJFhHcOL63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  print(f\"Prediction before training: f(6) = {model(testing_sample)}\")"
      ],
      "metadata": {
        "id": "NSnpilYJOOJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the training loop looks like this:"
      ],
      "metadata": {
        "id": "LIwPHcEuIxob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  # Obtain prediction\n",
        "\n",
        "  pred = model(x)\n",
        "\n",
        "  # 2. Compute loss\n",
        "  loss = custom_loss(pred, y)\n",
        "\n",
        "  # 3. Compute gradients\n",
        "  loss.backward()\n",
        "\n",
        "  # 4. Update parameters\n",
        "  optimizer.step()\n",
        "\n",
        "  # Set gradient to 0 for next computation\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch % 10 == 0:\n",
        "    print(f\"Epoch: {epoch}, loss = {loss}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  print(f\"Prediction after training: f(6) = {model(testing_sample)}\")\n"
      ],
      "metadata": {
        "id": "xh_8eTWzHM5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neural Network on Circle Dataset"
      ],
      "metadata": {
        "id": "zhJaWFMMdAF4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will build the following Neural Network with 2 input neurons, 3 neurons in the hidden layer and two output neurons:\n",
        "\n",
        "<img src=\"https://www.researchgate.net/publication/289479445/figure/fig1/AS:614019022991383@1523404951564/Example-for-an-artificial-neural-network-with-two-input-neurons-two-hidden-neurons-and.png\" width=300px>"
      ],
      "metadata": {
        "id": "5CnMuzE_3ftJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each neuron in the neural network is just a linear model + an activation function (which adds nonlinearity).\n",
        "\n",
        "All the neurons in a previous layer are connected to all the layers in the current layer.\n",
        "\n",
        "This means that the output of a neuron will be computed based on all the outputs of the neurons in the previous layer."
      ],
      "metadata": {
        "id": "50859qDqOVck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    # This defines the connections from input layer to hidden layer - 2 neruons to 3 neurons\n",
        "    self.fc1 = nn.Linear(in_features=2, out_features=3)\n",
        "\n",
        "    # This defines the connections from hidden layer to output layer - 3 neruons to 2 neurons\n",
        "    self.fc2 = nn.Linear(in_features=3, out_features=2)\n",
        "\n",
        "    # This is a commonly used nonlinearity\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "    # Activation functions which are more recent:\n",
        "    # self.activation = nn.GELU()\n",
        "    # self.activation = nn.Mish()\n",
        "    # self.activation = nn.ELU()\n",
        "\n",
        "    # Other activation functions (only used in specific cases):\n",
        "    # self.activation = nn.Tanh()\n",
        "    # self.activation = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, x):\n",
        "    # We pass through first layer\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    # We add nonlinearity\n",
        "    x = self.activation(x)\n",
        "\n",
        "    # We pass through output layer\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "2FIvJ9geJ_FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will train it to classify samples consisting of points inside or outside a circle. We will have 2 classes: $inside=0$ and $outside=1$.\n",
        "\n"
      ],
      "metadata": {
        "id": "_a7G7fD03uzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the code that generates the samples - you can ignore it\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define the circle parameters\n",
        "radius = 5\n",
        "center = (0, 0)\n",
        "\n",
        "# Generate the dataset\n",
        "num_samples = 2000\n",
        "\n",
        "# Generate random x, y points within a square\n",
        "x = torch.rand(num_samples) * 2 * radius - radius\n",
        "y = torch.rand(num_samples) * 2 * radius - radius\n",
        "\n",
        "# Calculate the Euclidean distance from each point to the center\n",
        "distances = torch.sqrt((x - center[0]) ** 2 + (y - center[1]) ** 2)\n",
        "\n",
        "# Assign labels based on whether points are inside or outside the circle\n",
        "labels = torch.where(distances <= radius, torch.zeros_like(distances), torch.ones_like(distances))\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "labels_train, labels_test = train_test_split(labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Plot the training and testing datasets\n",
        "plt.scatter(x_train[labels_train == 0], y_train[labels_train == 0], color='blue', label='Inside Circle (Train)')\n",
        "plt.scatter(x_train[labels_train == 1], y_train[labels_train == 1], color='red', label='Outside Circle (Train)')\n",
        "plt.scatter(x_test[labels_test == 0], y_test[labels_test == 0], color='cyan', label='Inside Circle (Test)')\n",
        "plt.scatter(x_test[labels_test == 1], y_test[labels_test == 1], color='orange', label='Outside Circle (Test)')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Dataset')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q8Ho7_M4MwcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Dataset class which stores samples and their labels."
      ],
      "metadata": {
        "id": "6aHk-uIMOEfO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class CircleDataset(Dataset):\n",
        "    def __init__(self, x, y, labels):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {\n",
        "            'coords': torch.tensor([self.x[idx], self.y[idx]]),\n",
        "            'label': self.labels[idx].long()\n",
        "        }\n",
        "\n",
        "        return sample"
      ],
      "metadata": {
        "id": "59Uq__pFODXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Dataset class in PyTorch represents a collection of data samples and labels. It is needed for the DataLoader class.\n",
        "\n",
        "The DataLoader class efficiently loads and manages the data during training or inference by providing features like batching and shuffling. These classes are commonly used in PyTorch. You can read more about them [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."
      ],
      "metadata": {
        "id": "N2WPr9DIQFf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CircleDataset(x_train, y_train, labels_train)\n",
        "test_dataset = CircleDataset(x_test, y_test, labels_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "W4PNm0VVOo-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will define an evaluation function which calculates the accuracy on the test set. This function will be used in the training loop in order to keep track of the evolution of the model on unseen data.\n",
        "\n",
        "We compute the accuracy manually for educational purposes. However, this is not necessary. There are already functions for computing evaluation metrics in the sklearn library. You can check them [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics). See [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) and [F1 score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)."
      ],
      "metadata": {
        "id": "chKFjo9rtOEn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model):\n",
        "  # Put model in evaluation mode\n",
        "  model.eval()\n",
        "\n",
        "  # For keeping track of number of correct predictions and total predictions\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for data in test_loader:\n",
        "      coords = data['coords'].to(device)\n",
        "      ground_truth = data['label'].to(device)\n",
        "\n",
        "      # We do not need to keep track of gradients while testing\n",
        "      with torch.no_grad():\n",
        "        pred = model(coords)\n",
        "\n",
        "      # From list of predicted scores we get the class with the highest score\n",
        "      _, predicted = torch.max(pred, 1)\n",
        "\n",
        "      # We count all the predictions which match the ground truth to get number of correct predictions\n",
        "      correct += (predicted == ground_truth).sum().item()\n",
        "      total += coords.shape[0]\n",
        "\n",
        "  accuracy = np.round(100 * correct / total, 2)\n",
        "\n",
        "  print(f\"Test Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "id": "EVPsSeVys_D9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The training loop will look very similar to the previous example.\n",
        "\n",
        "However, now we also iterate through the data loader which returns batches of random samples and their labels."
      ],
      "metadata": {
        "id": "kmWo5gO6dMaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cross Entropy Loss - commonly used for classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Hyperparameters\n",
        "learning_rate = 0.0005\n",
        "epochs = 10\n",
        "\n",
        "# 1. Initialize parameters\n",
        "model = Net()\n",
        "\n",
        "# Push model on device\n",
        "model.to(device)\n",
        "print(model)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  epoch_loss = 0\n",
        "  for data in train_loader:\n",
        "    # Put model in training mode\n",
        "    model.train()\n",
        "\n",
        "    coords = data['coords'].to(device)\n",
        "    ground_truth = data['label'].to(device)\n",
        "    pred = model(coords)\n",
        "\n",
        "    # 2. Compute loss\n",
        "    loss = criterion(pred, ground_truth)\n",
        "\n",
        "    # 3. Compute gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # 4. Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Set gradient to 0 for next computation\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    epoch_loss += loss\n",
        "\n",
        "  print(f\"Epoch: {epoch}, Training loss = {epoch_loss}\")\n",
        "  evaluate(model)\n"
      ],
      "metadata": {
        "id": "j-0Hp2cuQStQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 2** - Play with the hyperparameters (learning rate, number of epochs) and with the structure of the model (add more neurons in the hidden layer, add more layers) and see if you can improve the results. Maybe also change the optimizer.\n",
        "\n",
        "Try to apply only one change at a time and test it to see what improves the results and what decreases performance."
      ],
      "metadata": {
        "id": "9Jp-fa2qaxzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Neural Network for classification on the Iris Dataset"
      ],
      "metadata": {
        "id": "-vt-0U8eUoes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exercise 3** - Train a Neural Network for classification on the iris dataset.\n",
        "\n",
        "The iris dataset consists of measurements of sepal and petal lengths and widths for three different species of iris flowers: setosa, versicolor, and virginica.\n",
        "\n",
        "Your input to the model will be all these measurements (features) and you will have 3 flower classes."
      ],
      "metadata": {
        "id": "5dxIzyT_iXlB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code imports the dataset and creates the dataloaders that you need"
      ],
      "metadata": {
        "id": "bTTtByaoi6Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "data = iris.data\n",
        "labels = iris.target\n",
        "feature_names = iris.feature_names\n",
        "target_names = iris.target_names\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "T0d55VnkdWat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting the dataset"
      ],
      "metadata": {
        "id": "Roc52UG3kIor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create plots for different feature combinations\n",
        "feature_combinations = [(0, 1), (0, 2), (0, 3), (1, 2), (1, 3), (2, 3)]\n",
        "num_plots = len(feature_combinations)\n",
        "num_rows = (num_plots + 1) // 3  # Calculate the number of rows required for the subplot grid\n",
        "\n",
        "# Create the subplot grid\n",
        "fig, axs = plt.subplots(num_rows, 3, figsize=(10, num_rows * 3))\n",
        "\n",
        "# Plotting the dataset for each feature combination\n",
        "for i, (feat_idx1, feat_idx2) in enumerate(feature_combinations):\n",
        "    row = i // 3  # Determine the row index in the subplot grid\n",
        "    col = i % 3   # Determine the column index in the subplot grid\n",
        "    axs[row, col].scatter(data[:, feat_idx1], data[:, feat_idx2], c=labels, cmap='viridis')\n",
        "    axs[row, col].set_xlabel(feature_names[feat_idx1])\n",
        "    axs[row, col].set_ylabel(feature_names[feat_idx2])\n",
        "    axs[row, col].set_title(f\"{feature_names[feat_idx1]} vs {feature_names[feat_idx2]}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lBFMs_FRkHA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the Dataset class"
      ],
      "metadata": {
        "id": "hnydQ49XSg_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IrisDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample = {\n",
        "            'features': torch.tensor(self.features[idx], dtype=torch.float32),\n",
        "            'label': torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        }\n",
        "        return sample"
      ],
      "metadata": {
        "id": "SRMstEb5SfBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create the dataloaders for training set and testing set"
      ],
      "metadata": {
        "id": "Xnt1h_2MSoqm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test datasets\n",
        "iris_train_dataset = IrisDataset(x_train, y_train)\n",
        "iris_test_dataset = IrisDataset(x_test, y_test)\n",
        "\n",
        "# Create train and test data loaders\n",
        "iris_train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "iris_test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "mK2s5-EhSanq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your job is to construct the neural network and write the training and evaluation"
      ],
      "metadata": {
        "id": "1Svg0tNyjD1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MyNet, self).__init__()\n",
        "    # TODO - Write the layers of the network\n",
        "\n",
        "  def forward(self, x):\n",
        "    # TODO - Write the forward function - pass through each layer - do not forget about activation functions\n",
        "    pass"
      ],
      "metadata": {
        "id": "xI75fFt4drSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the training loop and the evaluation:\n",
        "\n",
        "* Define the hyperparameters\n",
        "* Define the loss function (criterion) - You can use already existing ones.\n",
        "* Define the optimizer\n",
        "* Initialize the model and train it\n",
        "* Evaluate the model's accuracy\n",
        "\n",
        "You can take inspiration from the previous example."
      ],
      "metadata": {
        "id": "ib7Km8EejG5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO - Write the training loop and evaluation code on the test set"
      ],
      "metadata": {
        "id": "K_YFJE7SeB97"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}